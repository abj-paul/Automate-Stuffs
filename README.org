:PROPERTIES:
:TOC:      :include all
:END:
#+options: \n:t
#+options: toc:nil
#+begin_export latex
  \clearpage \tableofcontents \clearpage
#+end_export

#+title: Automate & Chill!
#+date: <2021-10-07 sun>
#+author: Abhijit Paul

Feel free to raise issues if you encounter issues or require customization. I would love to help with any automation tasks.
:CONTENTS:

- [[#Collect datasets from google][Collect datasets from google]]
- [[#Auto-Sync Github][Auto-Sync Github]]
- [[#Automate NMAP analysis][Automate NMAP analysis]]
- [[#Convert Pdf To Image List][Convert Pdf To Image List]]
- [[#Process imageNet Dataset][Process imageNet Dataset]]
:END:

* About
A lot of automation tasks are needed in our day to day life. I will share them here to help others who might need them. Lets grow together.
Feel free to push your automation scripts here. I would love contributions. For any query, feel free to raise an issue.
* Automations
The following automations were done so far.
** Collect datasets from google
First, you need to install some packages as we will be using library to do the whole thing.
*** Download chromedriver
[[https://chromedriver.storage.googleapis.com/index.html?path=108.0.5359.71/][Download chromedriver from this site]] and unzip it.
#+begin_src bash
wget https://chromedriver.storage.googleapis.com/108.0.5359.71/chromedriver_linux64.zip # Download the latest chromedrive from the site if you want
unzip chromedriver_linux64.zip
ls -alh
#+end_src
No need to install it. We will use these code in our google-image-download package.
*** Install google-image-downdload
#+begin_src bash
pip install google_images_download
#+end_src
*** Download the dataset
Now that we are done downloading the packages, it is time to download the images! Note that, the following is a bash command.
#+begin_src bash
googleimagesdownload --keywords 'cloth stack' \
--limit 200 \
--size medium \
--chromedriver ./chromedriver \
--format jpg
#+end_src
Here, we are downloading images for "cloth stack".
** Auto-Sync Github
As we often forget to push-pull our git commits, conflict occurs, problem occurs. So it is a good idea to automatically commit them. Our script shows an example on how you can do it yourself.

*** Automatically run the script when shutting down the linux
If you want to automatically run the script just before shutting down the pc, add it in the ~/etc/rc0.d~ directory. For example,
#+begin_src text
/etc/rc0.d/sync_my_git.sh
sudo chmod u+x sync_my_git.sh
#+end_src

*** Automatically run the script when starting the linux
Let’s now consider a solution that takes advantage of the /etc/rc.d/rc.local file. Since this file already runs at startup, we can append a line that invokes our script:
#+begin_src text
sh /home/ec2-user/reboot_message.sh
#+end_src

For this to work, though, we need to ensure that the rc.local file itself is executable:
#+begin_src bash
$ chmod +x /etc/rc.d/rc.local
#+end_src

[[https://www.baeldung.com/linux/run-script-on-startup][Information Source]]
** Automate NMAP analysis
This site runs a bunch of nmap commands for a given site. It can help you generate reconnaisance analysis for a site easily.
The details of each nmap script are commented beside the script.
*** Installation
To install it, execute the following commands.
#+begin_src bash
  git clone https://github.com/abj-paul/Automate-Stuffs
  cd Automate-Stuffs
  sudo chmod u+x nmap-report-generator.sh
  ./nmap-report-generator.sh examplesite.com
#+end_src
*** Output
All analysis are stored in their separate files. Hopefully the names of the files help you recognize them. If you have some confusion as to what content a file have, you can view the command at the top of the file or you can just go to the script code. Each code is explained there.
#+begin_src text
├── automate.sh
└── examplesite.org
    ├── examplesite.org.all.txt
    ├── examplesite.org.domain.txt
    ├── examplesite.org.ids_all.txt
    ├── examplesite.org.mixed_port_scan.txt
    ├── examplesite.org.port_scan.txt
    ├── examplesite.org.random_servers.txt
    ├── examplesite.org.range_port_scan.txt
    ├── examplesite.org.scan_ack_port.txt
    ├── examplesite.org.scan_list_targets.txt
    ├── examplesite.org.scan_syn_port.txt
    ├── examplesite.org.scan_tcp_port.txt
    ├── examplesite.org.scan_udp_port.txt
    ├── examplesite.org.script_crossite.txt
    ├── examplesite.org.script_default.txt
    ├── examplesite.org.script_open_ports.txt
    ├── examplesite.org.script_sitemap.txt
    ├── examplesite.org.service_intensity.txt
    ├── examplesite.org.service.txt
    ├── examplesite.org.sitemap.txt
    ├── examplesite.org.target_specification.txt
    ├── examplesite.org.tcp_list_targets.txt
    └── examplesite.org.udp_list_targets.txt

1 directory, 24 files
#+end_src
** Convert Pdf To Image List
In many occassions, we need to convert a pdf to image list. Taking screenshot reduces the quality of the image. So this automation script was developed(I intensively used it when doing SRS. Because our 100+ diagrams were made in slide, taking SS of each of them and inserting them in the main doc was inefficient. So we converted slide to pdf and then, used this script to get all diagrams from the pdf.)
*** Installation
Do change the fileprefix and pdf file name in the code according to your need. 

To install it, execute the following commands.
#+begin_src bash
  git clone https://github.com/abj-paul/Automate-Stuffs
  cd Automate-Stuffs
  python3 convert-pdf-to-img.py
#+end_src
*** Output
As we can see, it converted our CRC diagram pdf file, crc.pdf into list of images.
#+begin_src text
├── crc_card_0.jpg
├── crc_card_10.jpg
├── crc_card_11.jpg
├── crc_card_12.jpg
├── crc_card_13.jpg
├── crc_card_14.jpg
├── crc_card_15.jpg
├── crc_card_16.jpg
├── crc_card_1.jpg
├── crc_card_2.jpg
├── crc_card_3.jpg
├── crc_card_4.jpg
├── crc_card_5.jpg
├── crc_card_6.jpg
├── crc_card_7.jpg
├── crc_card_8.jpg
├── crc_card_9.jpg
├── crc.pdf
└── script.py

0 directories, 19 files

#+end_src
** Process imageNet Dataset
~keras.utils.image_dataset_from_dir()~ requires all images to be in a directory one step below it. For example,
#+begin_src text
  - imageNet
	- Category1
	           - img_1.jpg
	           - img_2.jpg
	           - img_3.jpg
	           - img_4.jpg
	           - img_5.jpg
	           - img_6.jpg
#+end_src

But in [[https://image-net.org/download-images.php][imageNet dataset]], the images are in the following format. 

#+begin_src text
  - imageNet
	- Category1
	     - images
		   - img_1.jpg
		   - img_2.jpg
		   - img_3.jpg
		   - img_4.jpg
		   - img_5.jpg
		   - img_6.jpg
#+end_src

So We need move all images from ~/category*/images/~ directory to ~/Category*/~. The scrip simply does that. The algorithm is:
1. List all directory.
2. Go to directory.
3. List all images.
4. Move them to the desired folder.
*** Issues
If you are facing issues, just browse through the script and change the directory names. Also, let me know of the issue so that I can reflect changes to fix that.
:
